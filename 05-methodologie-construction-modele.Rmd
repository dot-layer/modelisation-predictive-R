# Méthodologie de construction de modèles


## Mise en contexte


(...) Ce qu'on a fait à date:

- Retour sur 1-2-3-4
- Donc: les jeux de données sont bien structurés (propres)




(...) Ce qu'on veut faire maintenant:

Supposons pour l'instant que notre variable réponse $Y$ est quantitative. En introduction du monographe, nous avons fait l'hypothèse qu'une $f$ connecte nos variables explicative $X$ à $Y$ de telle sorte que
$$
  Y \approx f(X).
$$
L'objectif principal, dans ce chapitre, est d'apprendre (ou plutôt d'approximer) la fonction $f$ à l'aide de la théorie de l'apprentissage statistique. C'EST QUOI CA? **CITE ESL et ISL** Nous supposons que le lecteur possède des connaissances de base en statistique (distribution, espérance, variance, etc).


(...) Librairies et références:

- modélisation (général): caret?
- modèles: glmnet, xgBoost

- ISL et ESL.

*Selon le modèle choisi.


(...) Division du chapitre:

Dans ce chapitre, nous abordons la gestion des données; l'identification de modèles adéquats; l'estimation de modèles (fonction de perte, compromis biais-variance); la sélection d'un modèle (AIC,BIC,validation croisée); et l'évaluation de ce modèle (erreur de généralisation). 


## Gestion des données

Pour plusieurs raisons, il est conseillé de séparer aléatoirement son jeu de données en trois partie distinctes : les jeux de données d'entraînement, de validation et de test.
Chacune des trois parties est associées à une étape de la construction du modèle. Les données d'entrainement serviront à estimer nos modèles; les données de validation à sélectionner un modèle; les données de test à évaluer le modèle final.
Lorsque le nombre d'observation le permet, la règle du pouce généralement employée est d'utiliser la moitié(e?) des observations pour l'entrainement et le quart pour chacune des deux autres étapes.

IMAGE

Il est important de garder en tête que ce n'est qu'une règle du pouce.
Si le jeu de données contient peu de signal (d'information) pour prédire $\mathbf{y}$, il se peut qu'en laissant de côté certaines observations, l'estimation des modèles soit trop déficiente pour être utile.
Les étapes des Chapitre **REF** permettent généralement aux scientifique des données de faire une idée de la situation.

On associe aux jeux de données d'entraînement l'*erreur d'entrainement*, qui est l'erreur qu'on minimise lors de l'estimation du modèle.
En contrepartie, les jeux de données de validation et de test servent tous deux à estimer l'*erreur de généralisation*, c'est-à-dire l'erreur faite sur de **nouvelles** données.
Cela explique d'ailleurs qu'il existe beaucoup de confusion concernant ces derniers et leur utilité.
Les données de validation servent à choisir un modèle parmi plusieurs, ce qui peut vouloir dire choisir le nombre d'interactions croisées dans un modèle linéaire généralisé ou le nombre de couches cachées dans un réseau de neurones.
Malgré que ce ne soit pas particulièrement conseillé, il peut arriver que l'on veuille re-mélangé les jeux d'entrainement et de validation lors du processus.
Il est absolument impératif toutefois de garder les données de test dans un coffre-fort bien cellé.
Sinon, notre estimation finale de l'*erreur de généralisation* pourrait être induement optimiste. Il faut toujours garder en tête que la mission du modèle est de prédire de **nouvelles** valeurs $\mathbf{y}$ à l'aide de **nouvelles** valeurs $\mathbf{X}$; l'erreur de généralisation est donc au coeur de nos préoccupations.

Lorsque trop peu de données sont disponible, l'étape de test doit souvent être abandonnée et des techniques plus sophistiquées peuvent nous permettre d'estimer l'erreur de généralisation à partir des données d'entrainement.
On verra toutefois que ces méthodes estiment l'*erreur de généralisation* moyenne conditionelle aux données $X$.
Ces dernières sont d'ailleurs expliquées en fin de chapitre.
D'ici là, nous utilisons $\mathbf{X}$ en référence aux données d'entrainement.


## Identification d'un modèle

Commençons d'abord en reformulant REF en tant qu'égalité stricte.
Pour ce faire, on introduit une quantité aléatoire $\varepsilon$ qui représente la variabilité non captée par notre modèle.
Cela donne ainsi l'équation
$$
  Y = f(X) + \varepsilon.
$$
Dans la grande majorité des cas, il est naturel de faire les deux hypothèses suivantes à propos de $\varepsilon$.
Tout d'abord, on suppose que sa valeur moyenne est nulle, c'est-à-dire $\mathbf{E}(\varepsilon) = 0$.
Ceci nous permet entre autre d'oublier $\varepsilon$ lorsque vient le temps de faire une prédiction.
Étant donné $X$, on s'attend à ce qu'en moyenne $Y$ soit égale à $f(X)$, *i.e.* $\mathbf{E}(Y) = f(X)$.
On stipule aussi souvent, à des fins de simplification, que $\varepsilon$ et $X$ sont indépendants.

Notons qu'en introduisant $\varepsilon$, on admet l'existence d'une erreur *irréductible* : même si nous réussissions à estimer $f$ parfaitement, il faudrait s'attendre à ce que nos prédictions ne soient pas nécéssairement parfaite.
Ceci s'explique par la présence de facteurs influençant $Y$ auxquels nous n'avons pas accès (qui ne sont pas mesurés) ou qui ne sont simplement pas mesurables; mais aussi par un choix de modèle $f$ qui ne permet pas de capturer l'essentiel de la relation entre $X$ et $Y$.
Ainsi, pour minimiser l'erreur dite *réductible* autant que possible, il est nécessaire d'accéder à un maximum d'information (pertinente! et si possible non-redondante) et de choisir une famille de modèles appropriée pour le problème qui nous intéresse.

On divise généralement les tâches en deux grandes catégories : la régression et la classification. **EXPLICATIONS**

**Exemples**

(littéralement sous forme d'exemple avec des dataset bébé)

  - régression linéaire (mention : bien comprendre les modèles linéaires est essentiel pour comprendre les modèles non-linéaire)
  - modèles lineaires généralisé (reg. logistique)
  - modèles additifs
  - arbres de décisions (boosted trees)
  - SVM (note : plus populaire en info)

**NOTE :** a-t-il été mention de...

- $g(Y) = f(X) + \epsilon$ -- modèle additif versus modèle multiplicatif?
- interprétabilité vs performance (souvent lié à inférence vs prédiction)


## Estimation d'un modèle

- Un mot rapide sur le split (train/test/val) et les différentes erreurs (de prédiction et de généralisation)
- fonction de perte (loss function/objective function)
- ajustement du modèle: minimisation de l'erreur de prédiction moyenne.
- explication avec un modèle simple : régression linéaire (ajuster les betas)
- Un mot très rapide sur la régularisation (l2 (ridge), l1 (lasso), l1+l2 (elastic net))



**Exemples (suite)**

  - modèles lineaires généralisé (glmnet)
  - modèles additifs (xgBoost)
  - arbres de décisions (boosted trees - xgBoost)
  - SVM (?)



## Sélection d'un modèle
- *erreur de généralization*
- estimation via la division du jeu de données (train/test/val) -- note sur caret qui permet la séparation
- estimation via CV (Jackknife et son évolution)
- estimation via bootstrap


**Exemples**

Un exemple pour chacune des trois méthodes.
